{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example on how you can use a jupyter notebook to train your model :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataloaders import load_cifar10\n",
    "from trainer import Trainer, compute_loss_and_accuracy\n",
    "from task2 import create_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_channels,\n",
    "                 num_classes):\n",
    "        \"\"\"\n",
    "            Is called when model is initialized.\n",
    "            Args:\n",
    "                image_channels. Number of color channels in image (3)\n",
    "                num_classes: Number of classes we want to predict (10)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        num_filters = 32  # Set number of filters in first conv layer\n",
    "        self.num_classes = num_classes\n",
    "        # Define the convolutional layers\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=image_channels,\n",
    "                out_channels=num_filters,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # The output of feature_extractor will be [batch_size, num_filters, 16, 16]\n",
    "        self.num_output_features = 32*32*32\n",
    "        # Initialize our last fully connected layer\n",
    "        # Inputs all extracted features from the convolutional layers\n",
    "        # Outputs num_classes predictions, 1 for each class.\n",
    "        # There is no need for softmax activation function, as this is\n",
    "        # included with nn.CrossEntropyLoss\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_output_features, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the model\n",
    "        Args:\n",
    "            x: Input image, shape: [batch_size, 3, 32, 32]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        out = self.feature_extractor(x)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.classifier(out)        \n",
    "        expected_shape = (batch_size, self.num_classes)\n",
    "        assert out.shape == (batch_size, self.num_classes),\\\n",
    "            f\"Expected output of forward pass to be: {expected_shape}, but got: {out.shape}\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PIL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9b635c5b954b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m \u001b[0;31m# Should be 5e-5 for LeNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mearly_stop_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExampleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m trainer = Trainer(\n",
      "\u001b[0;32m~/home/Datasyn/Ã˜ving 3/dataloaders.py\u001b[0m in \u001b[0;36mload_cifar10\u001b[0;34m(batch_size, validation_fraction)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     ])\n\u001b[0;32m---> 20\u001b[0;31m     transform_test = transforms.Compose([\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PIL' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2 # Should be 5e-5 for LeNet\n",
    "early_stop_count = 4\n",
    "dataloaders = load_cifar10(batch_size)\n",
    "model = ExampleModel(image_channels=3, num_classes=10)\n",
    "trainer = Trainer(\n",
    "    batch_size,\n",
    "    learning_rate,\n",
    "    early_stop_count,\n",
    "    epochs,\n",
    "    model,\n",
    "    dataloaders\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-492432242bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"task2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "create_plots(trainer, \"task2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
